{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","metadata":{"execution":{"iopub.status.busy":"2023-08-04T07:01:05.29611Z","iopub.execute_input":"2023-08-04T07:01:05.29744Z","iopub.status.idle":"2023-08-04T07:01:05.303359Z","shell.execute_reply.started":"2023-08-04T07:01:05.297387Z","shell.execute_reply":"2023-08-04T07:01:05.302052Z"},"jupyter":{"source_hidden":true},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 라이브러리 불러오기\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models import resnet18\nfrom torchvision import transforms\nimport torchaudio\nimport pandas as pd\nimport torch\nimport torch.nn as nn\n\nclass MonoToColor(nn.Module):\n    def __init__(self, num_channels=3):\n        super(MonoToColor, self).__init__()\n        self.num_channels = num_channels\n\n    def forward(self, tensor):\n        return tensor.repeat(self.num_channels, 1, 1)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##IDK what is wrong with that up cell\nimport torch\nimport subprocess\n\ndef GPU():\n    if torch.cuda.is_available() == True:\n        device = 'cuda'\n        templist = [1, 2, 3]\n        templist = torch.FloatTensor(templist).to(device)\n        print(\"Cuda torch working : \", end=\"\")\n        print(templist.is_cuda)\n        print(\"current device no. : \", end=\"\")\n        print(torch.cuda.current_device())\n        print(\"GPU device count : \", end=\"\")\n        print(torch.cuda.device_count())\n        print(\"GPU name : \", end=\"\")\n        print(torch.cuda.get_device_name(0))\n        print(\"device : \", device)\n        # Execute the nvidia-smi command using subprocess\n        try:\n            output = subprocess.check_output(['nvidia-smi']).decode('utf-8')\n            print(\"nvidia-smi output:\")\n            print(output)\n        except (subprocess.CalledProcessError, FileNotFoundError) as e:\n            print(\"Error executing nvidia-smi command:\", str(e))\n    elif torch.backends.mps.is_available() == True:\n        print(\"Apple device detected\\nActivating Apple Silicon GPU\")\n        device = torch.device(\"mps\")\n    else:\n        print(\"cant use gpu , activating cpu\")\n        device = 'cpu'\n\n    return device\ndevice = GPU()\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T07:01:05.327238Z","iopub.execute_input":"2023-08-04T07:01:05.327774Z","iopub.status.idle":"2023-08-04T07:01:05.44807Z","shell.execute_reply.started":"2023-08-04T07:01:05.327742Z","shell.execute_reply":"2023-08-04T07:01:05.44688Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset 클래스 정의\nclass UrbanSoundDataset(Dataset):\n    def __init__(self, annotations_file, audio_dir, transformation, target_sample_rate):\n        self.annotations = (annotations_file)\n        self.audio_dir = audio_dir\n        self.transformation = transformation\n        self.target_sample_rate = target_sample_rate\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, index):\n        audio_sample_path = self._get_audio_sample_path(index)\n        label = self._get_audio_sample_label(index)\n        signal, sr = torchaudio.load(audio_sample_path)\n        signal = self._resample_if_necessary(signal, sr)\n        signal = self._mix_down_if_necessary(signal)\n        signal = self._cut_if_necessary(signal)\n        signal = self._right_pad_if_necessary(signal)\n        signal = self.transformation(signal)\n        return signal, label\n\n    def _cut_if_necessary(self, signal):\n        if signal.shape[1] > self.target_sample_rate:\n            signal = signal[:, :self.target_sample_rate]\n        return signal\n\n    def _right_pad_if_necessary(self, signal):\n        length_signal = signal.shape[1]\n        if length_signal < self.target_sample_rate:\n            num_missing_samples = self.target_sample_rate - length_signal\n            last_dim_padding = (0, num_missing_samples)\n            signal = nn.functional.pad(signal, last_dim_padding)\n        return signal\n\n    def _resample_if_necessary(self, signal, sr):\n        if sr != self.target_sample_rate:\n            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n            signal = resampler(signal)\n        return signal\n\n    def _mix_down_if_necessary(self, signal):\n        if signal.shape[0] > 1:\n            signal = torch.mean(signal, dim=0, keepdim=True)\n        return signal\n    def _get_audio_sample_path(self, index):\n        fold = f\"fold{self.annotations.iloc[index, 5]}\"\n        file_name = self.annotations.iloc[index, 0]\n        audio_sample_path = os.path.join(self.audio_dir, fold, file_name)\n        return audio_sample_path\n\n    def _get_audio_sample_label(self, index):\n        return self.annotations.iloc[index, 6]","metadata":{"execution":{"iopub.status.busy":"2023-08-04T07:01:05.450169Z","iopub.execute_input":"2023-08-04T07:01:05.451393Z","iopub.status.idle":"2023-08-04T07:01:05.468344Z","shell.execute_reply.started":"2023-08-04T07:01:05.451245Z","shell.execute_reply":"2023-08-04T07:01:05.46706Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 데이터셋 및 데이터 로더 설정\nimport pandas as pd\n\n\n# Load the dataset\nANNOTATIONS_FILE = pd.read_csv('/kaggle/input/urbansound8k/UrbanSound8K.csv')\nAUDIO_DIR = \"/kaggle/input/urbansound8k\"\n\nSAMPLE_RATE = 22050\nBATCH_SIZE = 64\nNUM_WORKERS = 0\nPIN_MEMORY = True if torch.cuda.is_available() else False\n\nif torch.cuda.is_available():\n    device = \"cuda\"\nelse:\n    device = \"cpu\"\n\ntransformation = transforms.Compose([\n    torchaudio.transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_mels=128),\n    torchaudio.transforms.AmplitudeToDB(stype='power', top_db=80),\n    MonoToColor()\n])\n\n\nusd = UrbanSoundDataset(ANNOTATIONS_FILE, AUDIO_DIR, transformation, SAMPLE_RATE)\n\n# 데이터셋 분리\ndataset_size = len(usd)\ntrain_size = int(0.8 * dataset_size)\nval_size = int(0.1 * dataset_size)\ntest_size = dataset_size - train_size - val_size\ntrain_dataset, val_dataset, test_dataset = torch.utils.data.random_split(usd, [train_size, val_size, test_size])\n\n# 데이터 로더 생성\ntrain_loader = DataLoader(dataset=train_dataset,\n                            batch_size=BATCH_SIZE,\n                            shuffle=True,\n                            num_workers=NUM_WORKERS,\n                            pin_memory=PIN_MEMORY)\n\nval_loader = DataLoader(dataset=val_dataset,\n                            batch_size=BATCH_SIZE,\n                            shuffle=True,\n                            num_workers=NUM_WORKERS,\n                            pin_memory=PIN_MEMORY)\n\ntest_loader = DataLoader(dataset=test_dataset,\n                            batch_size=BATCH_SIZE,\n                            shuffle=True,\n                            num_workers=NUM_WORKERS,\n                            pin_memory=PIN_MEMORY)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-04T07:01:05.469596Z","iopub.execute_input":"2023-08-04T07:01:05.470036Z","iopub.status.idle":"2023-08-04T07:01:05.514748Z","shell.execute_reply.started":"2023-08-04T07:01:05.469989Z","shell.execute_reply":"2023-08-04T07:01:05.512038Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ResNet18 모델 설정\nmodel = resnet18(pretrained=False)\nmodel.fc = nn.Linear(512, 10)  # UrbanSound8K의 클래스 개수인 10으로 변경\n# Use multiple GPUs if available\nif torch.cuda.device_count() > 1:\n  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n  model = nn.DataParallel(model)\nmodel = model.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-04T07:01:05.519117Z","iopub.execute_input":"2023-08-04T07:01:05.519558Z","iopub.status.idle":"2023-08-04T07:01:05.740902Z","shell.execute_reply.started":"2023-08-04T07:01:05.519522Z","shell.execute_reply":"2023-08-04T07:01:05.738544Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 손실함수와 옵티마이저 설정\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T07:01:05.742795Z","iopub.execute_input":"2023-08-04T07:01:05.744049Z","iopub.status.idle":"2023-08-04T07:01:05.751006Z","shell.execute_reply.started":"2023-08-04T07:01:05.744004Z","shell.execute_reply":"2023-08-04T07:01:05.749837Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 학습률 스케줄러 설정\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T07:01:05.75318Z","iopub.execute_input":"2023-08-04T07:01:05.753712Z","iopub.status.idle":"2023-08-04T07:01:05.764146Z","shell.execute_reply.started":"2023-08-04T07:01:05.75367Z","shell.execute_reply":"2023-08-04T07:01:05.762999Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n# 최고 검증 정확도를 저장하기 위한 변수 설정\nbest_acc = 0.0\n\n# 모델 훈련 함수 정의\ndef train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs):\n    global best_acc\n\n    for epoch in range(num_epochs):\n        if epoch % 20 == 0:\n            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n            print('-' * 10)\n\n        # 각 에포크(epoch)은 학습 단계와 검증 단계를 거칩니다.\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # 모델을 학습 모드로 설정\n            else:\n                model.eval()   # 모델을 평가 모드로 설정\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # 데이터를 반복\n            for inputs, labels in tqdm(dataloaders[phase]):\n                #print(input.shape)\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # 매개변수 경사도를 0으로 설정\n                optimizer.zero_grad()\n\n                # 순전파\n                # 학습 시에만 연산 기록을 추적\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # 학습 단계인 경우 역전파 + 최적화\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # 통계를 계산\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            if epoch % 20 == 0:\n                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                    phase, epoch_loss, epoch_acc))\n\n            # 모델을 깊은 복사(deep copy)함\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        if epoch % 20 == 0:\n            print()\n\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # 가장 나은 모델 가중치를 불러옴\n    model.load_state_dict(best_model_wts)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-08-04T07:01:05.766272Z","iopub.execute_input":"2023-08-04T07:01:05.766724Z","iopub.status.idle":"2023-08-04T07:01:05.78351Z","shell.execute_reply.started":"2023-08-04T07:01:05.766685Z","shell.execute_reply":"2023-08-04T07:01:05.782366Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import copy\nNB_EPOCH = 100\n# 모델 훈련 시작\ndataloaders = {\"train\": train_loader, \"val\": val_loader}\n# define dataset_sizes\ndataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n\nbest_model = train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=NB_EPOCH)\n\n# 가장 좋은 모델 저장\ntorch.save(best_model.state_dict(), \"ResNet18_Best.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-08-04T07:01:05.787025Z","iopub.execute_input":"2023-08-04T07:01:05.787822Z","iopub.status.idle":"2023-08-04T07:07:14.816545Z","shell.execute_reply.started":"2023-08-04T07:01:05.787774Z","shell.execute_reply":"2023-08-04T07:07:14.815351Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 모델 평가 함수 정의\ndef test_model(model, test_loader, device):\n    model.eval()  # 모델을 평가 모드로 설정\n    correct = 0\n    total = 0\n    with torch.no_grad():  # 그래디언트 계산 비활성화\n        for inputs, labels in tqdm(test_loader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    print(f'Accuracy of the model on test images: {100 * correct / total}%')\n","metadata":{"execution":{"iopub.status.busy":"2023-08-04T07:07:54.030408Z","iopub.execute_input":"2023-08-04T07:07:54.030987Z","iopub.status.idle":"2023-08-04T07:07:54.043047Z","shell.execute_reply.started":"2023-08-04T07:07:54.030938Z","shell.execute_reply":"2023-08-04T07:07:54.040713Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 훈련 및 평가\ntest_model(best_model, test_loader, device)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-04T07:07:58.269639Z","iopub.execute_input":"2023-08-04T07:07:58.270059Z","iopub.status.idle":"2023-08-04T07:08:01.304642Z","shell.execute_reply.started":"2023-08-04T07:07:58.270025Z","shell.execute_reply":"2023-08-04T07:08:01.302472Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]}]}